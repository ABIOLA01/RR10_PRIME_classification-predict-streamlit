{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e091a001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Advanced Classification Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**YOUR NAME, YOUR SURNAME**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### EA - Twitter Sentiment Classification Challenge\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "- 1. analyse the supplied data;\n",
    "- 2. identify potential errors in the data and clean the existing data set;\n",
    "- 3. determine if additional features can be added to enrich the data set;\n",
    "- 4. build a model that is capable of forecasting the three hourly demand shortfalls;\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine what features were most important in the model’s prediction decision, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "\n",
    "Formally the problem statement was given to you, the senior data scientist, by your manager via email reads as follow:\n",
    "\n",
    "> With this context, EDSA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4fb6cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "186b329b",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68952306",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a69e11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import numpy as np #for basic data manipulation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  #for visualization.\n",
    "import seaborn as sns  # for visualization.\n",
    "import string\n",
    "from scipy import stats\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to silence unnecessary warnings\n",
    "# Libraries for data preparation and model building\n",
    "\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f2f3c",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810f0ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the df_train and df_test data\n",
    "df_train= pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd31234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>RT @darreljorstad: Funny as hell! Canada deman...</td>\n",
       "      <td>897853122080407553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>All the biggest lies about climate change and ...</td>\n",
       "      <td>925046776553529344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0         -1  RT @darreljorstad: Funny as hell! Canada deman...   \n",
       "1         -1  All the biggest lies about climate change and ...   \n",
       "\n",
       "              tweetid  \n",
       "0  897853122080407553  \n",
       "1  925046776553529344  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d84664",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 2. Data Cleaning\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, we will be cleaning the data. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14682f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(train, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(train))\n",
    "    filtered_data = train[(z_scores < threshold).all(axis=1)]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524b64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(train):\n",
    "    # Create a translation table with punctuation characters mapped to None\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    # Remove punctuation from each data point in the train\n",
    "    cleaned_data_train = [text.translate(translator) for text in data_train]\n",
    "    \n",
    "    return cleaned_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221d774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(train):\n",
    "    cleaned_data_train = []\n",
    "    for text in data_train:\n",
    "        # Remove special characters using regex\n",
    "        cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "        cleaned_data_train.append(cleaned_text)\n",
    "    \n",
    "    return cleaned_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a977cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "\n",
    "def analyze_hashtag_sentiment(hashtag, num_tweets):\n",
    "    # Twitter API credentials\n",
    "    consumer_key = 'YOUR_CONSUMER_KEY'\n",
    "    consumer_secret = 'YOUR_CONSUMER_SECRET'\n",
    "    access_token = 'YOUR_ACCESS_TOKEN'\n",
    "    access_token_secret = 'YOUR_ACCESS_TOKEN_SECRET'\n",
    "    \n",
    "    # Authenticate with Twitter API\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    # Fetch tweets with the given hashtag\n",
    "    tweets = tweepy.Cursor(api.search, q=hashtag, lang='en').items(num_tweets)\n",
    "    \n",
    "    # Analyze sentiments of the tweets\n",
    "    sentiments = []\n",
    "    for tweet in tweets:\n",
    "        text = tweet.text\n",
    "        blob = TextBlob(text)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        sentiments.append(sentiment)\n",
    "    \n",
    "    # Calculate average sentiment\n",
    "    avg_sentiment = sum(sentiments) / len(sentiments)\n",
    "    \n",
    "    return avg_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0702ff6f",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4286c",
   "metadata": {},
   "source": [
    "### We would start the EDA process by checking the shape and other basic information about the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c49ab31e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data -  (30759, 3)\n"
     ]
    }
   ],
   "source": [
    "#Check the shape of the data\n",
    "print('Shape of train data - ', df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733c746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train columns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['sentiment', 'message', 'tweetid'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the columns in the datasets\n",
    "print('df_train columns:')\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf10e2a",
   "metadata": {},
   "source": [
    "#### Next, we check the statistics for the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a93434d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30759 entries, 0 to 30758\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  30759 non-null  int64 \n",
      " 1   message    30759 non-null  object\n",
      " 2   tweetid    30759 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 721.0+ KB\n"
     ]
    }
   ],
   "source": [
    "## check df_train information (checking for null and datatypes of each column/feature)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22333a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
